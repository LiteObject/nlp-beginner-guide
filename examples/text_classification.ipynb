{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eab1cc97",
   "metadata": {},
   "source": [
    "# Text Classification with Machine Learning\n",
    "\n",
    "This notebook demonstrates how to build text classification models for categorizing documents.\n",
    "\n",
    "## What you'll learn:\n",
    "- Text feature extraction (Bag of Words, TF-IDF)\n",
    "- Multiple classification algorithms\n",
    "- Model evaluation and comparison\n",
    "- Handling imbalanced datasets\n",
    "- Building a complete classification pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9aee261",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a964b269",
   "metadata": {},
   "source": [
    "## Creating Sample Dataset\n",
    "We'll create a news classification dataset with different categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf7545cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample news articles for different categories\n",
    "sports_articles = [\n",
    "    \"The basketball team won their championship game with a score of 98-87\",\n",
    "    \"Football season starts next month with high expectations for the home team\",\n",
    "    \"Tennis player advances to semifinals after defeating opponent in straight sets\",\n",
    "    \"Baseball game postponed due to rain, rescheduled for tomorrow evening\",\n",
    "    \"Olympic swimmer breaks world record in 200m freestyle competition\",\n",
    "    \"Soccer match ends in draw after intense 90-minute battle\",\n",
    "    \"Hockey team trades star player to rival team for draft picks\",\n",
    "    \"Marathon runner completes race in personal best time despite challenging weather\",\n",
    "    \"Golf tournament concludes with surprise victory by amateur player\",\n",
    "    \"Boxing match scheduled for next weekend features heavyweight champions\"\n",
    "]\n",
    "\n",
    "technology_articles = [\n",
    "    \"New smartphone features advanced AI camera technology and 5G connectivity\",\n",
    "    \"Software company releases major update with improved security features\",\n",
    "    \"Artificial intelligence breakthrough enables more accurate medical diagnosis\",\n",
    "    \"Electric car manufacturer announces new battery technology with extended range\",\n",
    "    \"Tech startup develops innovative app for remote work collaboration\",\n",
    "    \"Quantum computing research shows promising results for encryption algorithms\",\n",
    "    \"Social media platform introduces new privacy controls for user data\",\n",
    "    \"Robotics company unveils autonomous delivery system for urban areas\",\n",
    "    \"Cloud computing service expands to new regions with enhanced performance\",\n",
    "    \"Virtual reality headset offers immersive experience for gaming and education\"\n",
    "]\n",
    "\n",
    "health_articles = [\n",
    "    \"Medical study reveals new treatment options for diabetes patients\",\n",
    "    \"Health experts recommend daily exercise for cardiovascular wellness\",\n",
    "    \"Vaccine research shows promising results in clinical trials\",\n",
    "    \"Nutrition guidelines updated to include more plant-based food options\",\n",
    "    \"Mental health awareness campaign launches in schools nationwide\",\n",
    "    \"Hospital introduces new surgical technique with faster recovery times\",\n",
    "    \"Pharmaceutical company develops innovative drug for rare disease treatment\",\n",
    "    \"Health insurance coverage expands to include preventive care services\",\n",
    "    \"Medical device helps patients monitor vital signs at home\",\n",
    "    \"Research indicates meditation benefits for stress reduction and sleep quality\"\n",
    "]\n",
    "\n",
    "# Create dataset\n",
    "texts = sports_articles + technology_articles + health_articles\n",
    "labels = ['sports'] * len(sports_articles) + ['technology'] * len(technology_articles) + ['health'] * len(health_articles)\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'text': texts,\n",
    "    'category': labels\n",
    "})\n",
    "\n",
    "print(f\"Dataset created with {len(df)} articles\")\n",
    "print(f\"Categories: {df['category'].value_counts().to_dict()}\")\n",
    "print(\"\\nFirst few examples:\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "160ab930",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da910c13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text length analysis\n",
    "df['text_length'] = df['text'].str.len()\n",
    "df['word_count'] = df['text'].str.split().str.len()\n",
    "\n",
    "# Visualizations\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "# Category distribution\n",
    "df['category'].value_counts().plot(kind='bar', ax=axes[0, 0], color='skyblue')\n",
    "axes[0, 0].set_title('Articles per Category')\n",
    "axes[0, 0].set_xlabel('Category')\n",
    "axes[0, 0].set_ylabel('Count')\n",
    "axes[0, 0].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Text length distribution\n",
    "df['text_length'].hist(bins=15, ax=axes[0, 1], color='lightcoral', alpha=0.7)\n",
    "axes[0, 1].set_title('Distribution of Text Length')\n",
    "axes[0, 1].set_xlabel('Characters')\n",
    "axes[0, 1].set_ylabel('Frequency')\n",
    "\n",
    "# Word count by category\n",
    "df.boxplot(column='word_count', by='category', ax=axes[1, 0])\n",
    "axes[1, 0].set_title('Word Count by Category')\n",
    "axes[1, 0].set_xlabel('Category')\n",
    "axes[1, 0].set_ylabel('Word Count')\n",
    "\n",
    "# Average text length by category\n",
    "avg_length = df.groupby('category')['text_length'].mean()\n",
    "avg_length.plot(kind='bar', ax=axes[1, 1], color='lightgreen')\n",
    "axes[1, 1].set_title('Average Text Length by Category')\n",
    "axes[1, 1].set_xlabel('Category')\n",
    "axes[1, 1].set_ylabel('Average Characters')\n",
    "axes[1, 1].tick_params(axis='x', rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Dataset Statistics:\")\n",
    "print(df.groupby('category')[['text_length', 'word_count']].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "274f0827",
   "metadata": {},
   "source": [
    "## Feature Extraction\n",
    "Converting text to numerical features that machine learning algorithms can understand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "626f19d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data\n",
    "X = df['text']\n",
    "y = df['category']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
    "\n",
    "print(f\"Training set: {len(X_train)} samples\")\n",
    "print(f\"Test set: {len(X_test)} samples\")\n",
    "print(f\"Training distribution: {pd.Series(y_train).value_counts().to_dict()}\")\n",
    "print(f\"Test distribution: {pd.Series(y_test).value_counts().to_dict()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a7f35e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method 1: Bag of Words (Count Vectorizer)\n",
    "count_vectorizer = CountVectorizer(max_features=500, stop_words='english', lowercase=True)\n",
    "X_train_counts = count_vectorizer.fit_transform(X_train)\n",
    "X_test_counts = count_vectorizer.transform(X_test)\n",
    "\n",
    "print(\"Bag of Words Features:\")\n",
    "print(f\"Feature matrix shape: {X_train_counts.shape}\")\n",
    "print(f\"Number of unique words: {len(count_vectorizer.vocabulary_)}\")\n",
    "print(f\"Sample feature names: {list(count_vectorizer.get_feature_names_out())[:10]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebdb45ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method 2: TF-IDF (Term Frequency-Inverse Document Frequency)\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=500, stop_words='english', lowercase=True)\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = tfidf_vectorizer.transform(X_test)\n",
    "\n",
    "print(\"TF-IDF Features:\")\n",
    "print(f\"Feature matrix shape: {X_train_tfidf.shape}\")\n",
    "print(f\"Number of unique words: {len(tfidf_vectorizer.vocabulary_)}\")\n",
    "\n",
    "# Show top TF-IDF features for each category\n",
    "def show_top_features(vectorizer, X, y, category, top_n=5):\n",
    "    \"\"\"Show top features for a specific category\"\"\"\n",
    "    # Get indices for the category\n",
    "    category_indices = [i for i, label in enumerate(y) if label == category]\n",
    "    \n",
    "    # Sum TF-IDF scores for the category\n",
    "    category_tfidf = X[category_indices].sum(axis=0).A1\n",
    "    \n",
    "    # Get feature names\n",
    "    feature_names = vectorizer.get_feature_names_out()\n",
    "    \n",
    "    # Get top features\n",
    "    top_indices = category_tfidf.argsort()[-top_n:][::-1]\n",
    "    top_features = [(feature_names[i], category_tfidf[i]) for i in top_indices]\n",
    "    \n",
    "    return top_features\n",
    "\n",
    "print(\"\\nTop TF-IDF features by category:\")\n",
    "for category in df['category'].unique():\n",
    "    top_features = show_top_features(tfidf_vectorizer, X_train_tfidf, y_train, category)\n",
    "    print(f\"\\n{category.upper()}:\")\n",
    "    for feature, score in top_features:\n",
    "        print(f\"  {feature}: {score:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3383978",
   "metadata": {},
   "source": [
    "## Building Classification Models\n",
    "We'll compare different algorithms to see which works best for our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c91d55b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define classifiers\n",
    "classifiers = {\n",
    "    'Naive Bayes': MultinomialNB(),\n",
    "    'Logistic Regression': LogisticRegression(random_state=42, max_iter=1000),\n",
    "    'SVM': SVC(random_state=42, kernel='linear'),\n",
    "    'Random Forest': RandomForestClassifier(random_state=42, n_estimators=100)\n",
    "}\n",
    "\n",
    "# Train and evaluate models with both feature types\n",
    "results = {}\n",
    "\n",
    "for feature_type, (X_train_feat, X_test_feat) in [('Count', (X_train_counts, X_test_counts)), \n",
    "                                                   ('TF-IDF', (X_train_tfidf, X_test_tfidf))]:\n",
    "    results[feature_type] = {}\n",
    "    \n",
    "    for name, classifier in classifiers.items():\n",
    "        # Train the model\n",
    "        classifier.fit(X_train_feat, y_train)\n",
    "        \n",
    "        # Make predictions\n",
    "        y_pred = classifier.predict(X_test_feat)\n",
    "        \n",
    "        # Calculate accuracy\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        \n",
    "        # Store results\n",
    "        results[feature_type][name] = {\n",
    "            'accuracy': accuracy,\n",
    "            'predictions': y_pred,\n",
    "            'model': classifier\n",
    "        }\n",
    "        \n",
    "        print(f\"{feature_type} - {name}: {accuracy:.3f}\")\n",
    "\n",
    "print(\"\\nModel training completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfb102b9",
   "metadata": {},
   "source": [
    "## Model Evaluation and Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e01845f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comparison visualization\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "# Accuracy comparison\n",
    "count_accuracies = [results['Count'][name]['accuracy'] for name in classifiers.keys()]\n",
    "tfidf_accuracies = [results['TF-IDF'][name]['accuracy'] for name in classifiers.keys()]\n",
    "\n",
    "x = np.arange(len(classifiers))\n",
    "width = 0.35\n",
    "\n",
    "axes[0].bar(x - width/2, count_accuracies, width, label='Count Vectorizer', color='skyblue')\n",
    "axes[0].bar(x + width/2, tfidf_accuracies, width, label='TF-IDF', color='lightcoral')\n",
    "axes[0].set_xlabel('Classifiers')\n",
    "axes[0].set_ylabel('Accuracy')\n",
    "axes[0].set_title('Model Performance Comparison')\n",
    "axes[0].set_xticks(x)\n",
    "axes[0].set_xticklabels(classifiers.keys(), rotation=45)\n",
    "axes[0].legend()\n",
    "axes[0].set_ylim(0, 1)\n",
    "\n",
    "# Add value labels on bars\n",
    "for i, (count_acc, tfidf_acc) in enumerate(zip(count_accuracies, tfidf_accuracies)):\n",
    "    axes[0].text(i - width/2, count_acc + 0.01, f'{count_acc:.3f}', ha='center', va='bottom')\n",
    "    axes[0].text(i + width/2, tfidf_acc + 0.01, f'{tfidf_acc:.3f}', ha='center', va='bottom')\n",
    "\n",
    "# Find best model\n",
    "best_feature_type = 'TF-IDF' if max(tfidf_accuracies) > max(count_accuracies) else 'Count'\n",
    "best_classifier = list(classifiers.keys())[np.argmax(results[best_feature_type][name]['accuracy'] for name in classifiers.keys())]\n",
    "best_accuracy = results[best_feature_type][best_classifier]['accuracy']\n",
    "\n",
    "print(f\"Best model: {best_classifier} with {best_feature_type} features\")\n",
    "print(f\"Best accuracy: {best_accuracy:.3f}\")\n",
    "\n",
    "# Confusion matrix for best model\n",
    "best_predictions = results[best_feature_type][best_classifier]['predictions']\n",
    "cm = confusion_matrix(y_test, best_predictions)\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=axes[1],\n",
    "            xticklabels=df['category'].unique(),\n",
    "            yticklabels=df['category'].unique())\n",
    "axes[1].set_title(f'Confusion Matrix - {best_classifier} ({best_feature_type})')\n",
    "axes[1].set_xlabel('Predicted')\n",
    "axes[1].set_ylabel('Actual')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac0883d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detailed classification report for best model\n",
    "print(f\"Detailed Classification Report - {best_classifier} ({best_feature_type}):\")\n",
    "print(\"=\" * 60)\n",
    "print(classification_report(y_test, best_predictions))\n",
    "\n",
    "# Show some predictions\n",
    "print(\"\\nSample Predictions:\")\n",
    "print(\"=\" * 40)\n",
    "for i, (text, true_label, pred_label) in enumerate(zip(X_test, y_test, best_predictions)):\n",
    "    if i < 5:  # Show first 5 predictions\n",
    "        status = \"✓\" if true_label == pred_label else \"✗\"\n",
    "        print(f\"{status} Text: {text[:60]}...\")\n",
    "        print(f\"  True: {true_label}, Predicted: {pred_label}\")\n",
    "        print(\"-\" * 40)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "567cc2f1",
   "metadata": {},
   "source": [
    "## Building a Complete Classification Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f389ff44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a pipeline with the best performing combination\n",
    "if best_feature_type == 'TF-IDF':\n",
    "    vectorizer = TfidfVectorizer(max_features=500, stop_words='english', lowercase=True)\n",
    "else:\n",
    "    vectorizer = CountVectorizer(max_features=500, stop_words='english', lowercase=True)\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('vectorizer', vectorizer),\n",
    "    ('classifier', classifiers[best_classifier])\n",
    "])\n",
    "\n",
    "# Train the pipeline\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Test the pipeline\n",
    "pipeline_predictions = pipeline.predict(X_test)\n",
    "pipeline_accuracy = accuracy_score(y_test, pipeline_predictions)\n",
    "\n",
    "print(f\"Pipeline Accuracy: {pipeline_accuracy:.3f}\")\n",
    "\n",
    "# Function to classify new text\n",
    "def classify_text(text):\n",
    "    \"\"\"\n",
    "    Classify a new piece of text.\n",
    "    \n",
    "    Args:\n",
    "        text (str): Text to classify\n",
    "    \n",
    "    Returns:\n",
    "        str: Predicted category\n",
    "    \"\"\"\n",
    "    prediction = pipeline.predict([text])[0]\n",
    "    probabilities = pipeline.predict_proba([text])[0]\n",
    "    confidence = max(probabilities)\n",
    "    \n",
    "    return prediction, confidence\n",
    "\n",
    "# Test with new examples\n",
    "test_texts = [\n",
    "    \"The soccer team scored three goals in the first half of the match\",\n",
    "    \"Researchers develop new machine learning algorithm for data analysis\",\n",
    "    \"Clinical trials show positive results for new cancer treatment drug\"\n",
    "]\n",
    "\n",
    "print(\"\\nClassifying New Texts:\")\n",
    "print(\"=\" * 40)\n",
    "for text in test_texts:\n",
    "    prediction, confidence = classify_text(text)\n",
    "    print(f\"Text: {text}\")\n",
    "    print(f\"Predicted Category: {prediction} (confidence: {confidence:.3f})\")\n",
    "    print(\"-\" * 40)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3611d49",
   "metadata": {},
   "source": [
    "## Cross-Validation for Robust Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf2ac24f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform cross-validation on the full dataset\n",
    "cv_scores = cross_val_score(pipeline, X, y, cv=5, scoring='accuracy')\n",
    "\n",
    "print(\"Cross-Validation Results:\")\n",
    "print(f\"Scores: {cv_scores}\")\n",
    "print(f\"Mean accuracy: {cv_scores.mean():.3f} (+/- {cv_scores.std() * 2:.3f})\")\n",
    "\n",
    "# Visualize CV scores\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(range(1, 6), cv_scores, color='lightblue', alpha=0.7)\n",
    "plt.axhline(y=cv_scores.mean(), color='red', linestyle='--', label=f'Mean: {cv_scores.mean():.3f}')\n",
    "plt.xlabel('Cross-Validation Fold')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Cross-Validation Scores')\n",
    "plt.legend()\n",
    "plt.ylim(0, 1)\n",
    "\n",
    "# Add value labels on bars\n",
    "for i, score in enumerate(cv_scores):\n",
    "    plt.text(i + 1, score + 0.01, f'{score:.3f}', ha='center', va='bottom')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dfef3aa",
   "metadata": {},
   "source": [
    "## Feature Importance Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d08f605",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For linear models, we can analyze feature importance\n",
    "if best_classifier in ['Logistic Regression', 'SVM']:\n",
    "    # Get feature names\n",
    "    feature_names = pipeline.named_steps['vectorizer'].get_feature_names_out()\n",
    "    \n",
    "    # Get coefficients\n",
    "    if hasattr(pipeline.named_steps['classifier'], 'coef_'):\n",
    "        coefficients = pipeline.named_steps['classifier'].coef_\n",
    "        \n",
    "        # Plot top features for each class\n",
    "        fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
    "        \n",
    "        classes = pipeline.classes_\n",
    "        \n",
    "        for idx, (class_name, ax) in enumerate(zip(classes, axes)):\n",
    "            # Get top positive and negative coefficients\n",
    "            class_coef = coefficients[idx]\n",
    "            top_indices = np.argsort(np.abs(class_coef))[-10:]\n",
    "            top_features = [(feature_names[i], class_coef[i]) for i in top_indices]\n",
    "            \n",
    "            # Sort by coefficient value\n",
    "            top_features.sort(key=lambda x: x[1])\n",
    "            \n",
    "            features, values = zip(*top_features)\n",
    "            colors = ['red' if v < 0 else 'green' for v in values]\n",
    "            \n",
    "            ax.barh(range(len(features)), values, color=colors, alpha=0.7)\n",
    "            ax.set_yticks(range(len(features)))\n",
    "            ax.set_yticklabels(features)\n",
    "            ax.set_title(f'Top Features for {class_name.title()}')\n",
    "            ax.set_xlabel('Coefficient Value')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        print(\"Feature Importance Analysis:\")\n",
    "        print(\"Green bars: Positive association with class\")\n",
    "        print(\"Red bars: Negative association with class\")\n",
    "        \n",
    "elif best_classifier == 'Random Forest':\n",
    "    # For Random Forest, show feature importance\n",
    "    feature_names = pipeline.named_steps['vectorizer'].get_feature_names_out()\n",
    "    importances = pipeline.named_steps['classifier'].feature_importances_\n",
    "    \n",
    "    # Get top 20 most important features\n",
    "    top_indices = np.argsort(importances)[-20:]\n",
    "    top_features = [(feature_names[i], importances[i]) for i in top_indices]\n",
    "    top_features.sort(key=lambda x: x[1])\n",
    "    \n",
    "    features, values = zip(*top_features)\n",
    "    \n",
    "    plt.figure(figsize=(10, 8))\n",
    "    plt.barh(range(len(features)), values, color='skyblue', alpha=0.7)\n",
    "    plt.yticks(range(len(features)), features)\n",
    "    plt.xlabel('Feature Importance')\n",
    "    plt.title('Top 20 Most Important Features (Random Forest)')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bca9a97",
   "metadata": {},
   "source": [
    "## Interactive Classification Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d15a73eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def interactive_classifier():\n",
    "    \"\"\"\n",
    "    Interactive function to classify user input.\n",
    "    \"\"\"\n",
    "    print(\"Text Classification Demo\")\n",
    "    print(\"=\" * 30)\n",
    "    print(\"Categories: sports, technology, health\")\n",
    "    print(\"Enter your text below (or 'quit' to stop):\\n\")\n",
    "    \n",
    "    while True:\n",
    "        user_text = input(\"Enter text: \")\n",
    "        \n",
    "        if user_text.lower() == 'quit':\n",
    "            print(\"Thanks for using the classifier!\")\n",
    "            break\n",
    "        \n",
    "        if user_text.strip():\n",
    "            prediction, confidence = classify_text(user_text)\n",
    "            print(f\"Predicted Category: {prediction}\")\n",
    "            print(f\"Confidence: {confidence:.3f}\")\n",
    "            print(\"-\" * 30)\n",
    "        else:\n",
    "            print(\"Please enter some text.\")\n",
    "\n",
    "# For demonstration purposes, let's test with predefined examples\n",
    "demo_texts = [\n",
    "    \"The quarterback threw a perfect pass for a touchdown\",\n",
    "    \"Scientists discover new way to edit genes using CRISPR technology\",\n",
    "    \"Regular exercise can help prevent heart disease and diabetes\"\n",
    "]\n",
    "\n",
    "print(\"Demo Classification Results:\")\n",
    "print(\"=\" * 40)\n",
    "for text in demo_texts:\n",
    "    prediction, confidence = classify_text(text)\n",
    "    print(f\"Text: {text}\")\n",
    "    print(f\"Category: {prediction} (confidence: {confidence:.3f})\")\n",
    "    print(\"-\" * 40)\n",
    "\n",
    "# Uncomment the line below to run the interactive classifier\n",
    "# interactive_classifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a1c3ce6",
   "metadata": {},
   "source": [
    "## Key Takeaways\n",
    "\n",
    "1. **Feature extraction** is crucial - TF-IDF often performs better than simple word counts\n",
    "2. **Different algorithms** have different strengths - linear models work well for text classification\n",
    "3. **Evaluation** should include multiple metrics, not just accuracy\n",
    "4. **Cross-validation** provides a more robust estimate of model performance\n",
    "5. **Pipelines** make it easy to combine preprocessing and modeling steps\n",
    "6. **Feature importance** analysis helps understand what the model has learned\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "- Try with larger datasets for better performance\n",
    "- Experiment with n-grams (bigrams, trigrams)\n",
    "- Use word embeddings (Word2Vec, GloVe) as features\n",
    "- Try deep learning approaches with neural networks\n",
    "- Handle imbalanced datasets with appropriate techniques"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
