{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9636b405",
   "metadata": {},
   "source": [
    "# Data Cleaning Demo: Spam Dataset\n",
    "\n",
    "This notebook demonstrates practical data cleaning techniques using the spam.csv dataset.\n",
    "We'll walk through:\n",
    "- Loading and exploring the data\n",
    "- Handling missing values\n",
    "- Removing duplicates\n",
    "- Data type conversion\n",
    "- Text cleaning\n",
    "- Normalization\n",
    "- Validation and quality checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "40b57de6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported successfully!\n"
     ]
    }
   ],
   "source": [
    "# Import Required Libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# import warnings\n",
    "\n",
    "# warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "print(\"Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54909de5",
   "metadata": {},
   "source": [
    "## 1. Load and Explore the Data\n",
    "\n",
    "First, let's load the spam.csv dataset and get an overview of its structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1b76d48b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Shape: (5572, 5)\n",
      "\n",
      "First few rows:\n",
      "  label                                            message Unnamed: 2  \\\n",
      "0   ham  Go until jurong point, crazy.. Available only ...        NaN   \n",
      "1   ham                      Ok lar... Joking wif u oni...        NaN   \n",
      "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...        NaN   \n",
      "3   ham  U dun say so early hor... U c already then say...        NaN   \n",
      "4   ham  Nah I don't think he goes to usf, he lives aro...        NaN   \n",
      "\n",
      "  Unnamed: 3 Unnamed: 4  \n",
      "0        NaN        NaN  \n",
      "1        NaN        NaN  \n",
      "2        NaN        NaN  \n",
      "3        NaN        NaN  \n",
      "4        NaN        NaN  \n",
      "\n",
      "Column Names and Types:\n",
      "label         object\n",
      "message       object\n",
      "Unnamed: 2    object\n",
      "Unnamed: 3    object\n",
      "Unnamed: 4    object\n",
      "dtype: object\n",
      "\n",
      "Dataset Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5572 entries, 0 to 5571\n",
      "Data columns (total 5 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   label       5572 non-null   object\n",
      " 1   message     5572 non-null   object\n",
      " 2   Unnamed: 2  50 non-null     object\n",
      " 3   Unnamed: 3  12 non-null     object\n",
      " 4   Unnamed: 4  6 non-null      object\n",
      "dtypes: object(5)\n",
      "memory usage: 217.8+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset with proper encoding\n",
    "df = pd.read_csv(\"../data/spam.csv\", sep=\",\", encoding=\"latin-1\")\n",
    "\n",
    "# Rename columns for clarity\n",
    "df.rename(columns={\"v1\": \"label\", \"v2\": \"message\"}, inplace=True)\n",
    "\n",
    "# Display basic information\n",
    "print(\"Dataset Shape:\", df.shape)\n",
    "print(\"\\nFirst few rows:\")\n",
    "print(df.head())\n",
    "print(\"\\nColumn Names and Types:\")\n",
    "print(df.dtypes)\n",
    "print(\"\\nDataset Info:\")\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a34d138e",
   "metadata": {},
   "source": [
    "## 2. Check for Missing Values\n",
    "\n",
    "Identify any missing or null values in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6e4462ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing Values Count:\n",
      "label            0\n",
      "message          0\n",
      "Unnamed: 2    5522\n",
      "Unnamed: 3    5560\n",
      "Unnamed: 4    5566\n",
      "dtype: int64\n",
      "\n",
      "Percentage of Missing Values:\n",
      "label          0.000000\n",
      "message        0.000000\n",
      "Unnamed: 2    99.102656\n",
      "Unnamed: 3    99.784637\n",
      "Unnamed: 4    99.892319\n",
      "dtype: float64\n",
      "\n",
      "Total missing values: 16648\n"
     ]
    }
   ],
   "source": [
    "# Check for missing values\n",
    "print(\"Missing Values Count:\")\n",
    "print(df.isnull().sum())\n",
    "print(\"\\nPercentage of Missing Values:\")\n",
    "missing_percent = (df.isnull().sum() / len(df)) * 100\n",
    "print(missing_percent)\n",
    "print(\"\\nTotal missing values:\", df.isnull().sum().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1127f380",
   "metadata": {},
   "source": [
    "## 3. Identify and Remove Duplicates\n",
    "\n",
    "Check for and remove duplicate rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "efd9abba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of duplicate rows: 403\n",
      "Duplicate rows (if any):\n",
      "     label                                            message Unnamed: 2  \\\n",
      "2     spam  Free entry in 2 a wkly comp to win FA Cup fina...        NaN   \n",
      "7      ham  As per your request 'Melle Melle (Oru Minnamin...        NaN   \n",
      "8     spam  WINNER!! As a valued network customer you have...        NaN   \n",
      "9     spam  Had your mobile 11 months or more? U R entitle...        NaN   \n",
      "11    spam  SIX chances to win CASH! From 100 to 20,000 po...        NaN   \n",
      "...    ...                                                ...        ...   \n",
      "5524  spam  You are awarded a SiPix Digital Camera! call 0...        NaN   \n",
      "5535   ham  I know you are thinkin malaria. But relax, chi...        NaN   \n",
      "5539   ham                         Just sleeping..and surfing        NaN   \n",
      "5553   ham                        Hahaha..use your brain dear        NaN   \n",
      "5558   ham                             Sorry, I'll call later        NaN   \n",
      "\n",
      "     Unnamed: 3 Unnamed: 4  \n",
      "2           NaN        NaN  \n",
      "7           NaN        NaN  \n",
      "8           NaN        NaN  \n",
      "9           NaN        NaN  \n",
      "11          NaN        NaN  \n",
      "...         ...        ...  \n",
      "5524        NaN        NaN  \n",
      "5535        NaN        NaN  \n",
      "5539        NaN        NaN  \n",
      "5553        NaN        NaN  \n",
      "5558        NaN        NaN  \n",
      "\n",
      "[684 rows x 5 columns]\n",
      "\n",
      "Rows removed: 403\n",
      "Dataset shape after removing duplicates: (5169, 5)\n"
     ]
    }
   ],
   "source": [
    "# Check for duplicates\n",
    "print(\"Number of duplicate rows:\", df.duplicated().sum())\n",
    "print(\"Duplicate rows (if any):\")\n",
    "print(df[df.duplicated(keep=False)])\n",
    "\n",
    "# Remove duplicates\n",
    "df_before = len(df)\n",
    "df.drop_duplicates(inplace=True)\n",
    "df_after = len(df)\n",
    "\n",
    "print(f\"\\nRows removed: {df_before - df_after}\")\n",
    "print(f\"Dataset shape after removing duplicates: {df.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f121e1f7",
   "metadata": {},
   "source": [
    "## 4. Data Type Conversion\n",
    "\n",
    "Ensure columns have appropriate data types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ce807f71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Data Types:\n",
      "label         object\n",
      "message       object\n",
      "Unnamed: 2    object\n",
      "Unnamed: 3    object\n",
      "Unnamed: 4    object\n",
      "dtype: object\n",
      "Dropped columns: ['Unnamed: 2', 'Unnamed: 3', 'Unnamed: 4']\n",
      "\n",
      "Updated Data Types:\n",
      "label      category\n",
      "message      object\n",
      "dtype: object\n",
      "\n",
      "Label value counts:\n",
      "label\n",
      "ham     4516\n",
      "spam     653\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check current data types\n",
    "print(\"Current Data Types:\")\n",
    "print(df.dtypes)\n",
    "\n",
    "# Convert label to categorical (spam/ham)\n",
    "df[\"label\"] = df[\"label\"].astype(\"category\")\n",
    "\n",
    "# Ensure message column is string type\n",
    "df[\"message\"] = df[\"message\"].astype(str)\n",
    "\n",
    "# Drop any columns that are not needed (like column indices added by pandas)\n",
    "columns_to_drop = [col for col in df.columns if col.startswith(\"Unnamed\")]\n",
    "if columns_to_drop:\n",
    "    df.drop(columns=columns_to_drop, inplace=True)\n",
    "    print(f\"Dropped columns: {columns_to_drop}\")\n",
    "\n",
    "print(\"\\nUpdated Data Types:\")\n",
    "print(df.dtypes)\n",
    "print(\"\\nLabel value counts:\")\n",
    "print(df[\"label\"].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "020db91b",
   "metadata": {},
   "source": [
    "## 5. Text Data Cleaning\n",
    "\n",
    "Clean the text messages by removing special characters, URLs, extra whitespace, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9a6adb1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample of original messages:\n",
      "['Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat...'\n",
      " 'Ok lar... Joking wif u oni...'\n",
      " \"Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive entry question(std txt rate)T&C's apply 08452810075over18's\"]\n",
      "\n",
      "Sample of cleaned messages:\n",
      "['Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat...'\n",
      " 'Ok lar... Joking wif u oni...'\n",
      " \"Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive entry question(std txt rate)T&C's apply 08452810075over18's\"]\n",
      "\n",
      "Empty messages after cleaning: 0\n"
     ]
    }
   ],
   "source": [
    "# Function to clean text\n",
    "def clean_text(text):\n",
    "    \"\"\"\n",
    "    Clean text by:\n",
    "    - Converting to lowercase\n",
    "    - Removing URLs\n",
    "    - Removing HTML tags\n",
    "    - Removing special characters and punctuation\n",
    "    - Removing extra whitespace\n",
    "    \"\"\"\n",
    "    # Convert to lowercase\n",
    "    # text = str(text).lower()\n",
    "\n",
    "    # Remove URLs\n",
    "    # text = re.sub(r\"http\\S+|www\\S+|https\\S+\", \"\", text, flags=re.MULTILINE)\n",
    "\n",
    "    # Remove HTML tags\n",
    "    # text = re.sub(r\"<[^>]+>\", \"\", text)\n",
    "\n",
    "    # Remove email addresses\n",
    "    # text = re.sub(r\"\\S+@\\S+\", \"\", text)\n",
    "\n",
    "    # Remove special characters and punctuation (keep alphanumeric and spaces)\n",
    "    # text = re.sub(r\"[^\\w\\s]\", \"\", text)\n",
    "\n",
    "    # Remove extra whitespace\n",
    "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
    "\n",
    "    return text\n",
    "\n",
    "\n",
    "# Apply cleaning\n",
    "print(\"Sample of original messages:\")\n",
    "print(df[\"message\"].head(3).values)\n",
    "\n",
    "df[\"message_cleaned\"] = df[\"message\"].apply(clean_text)\n",
    "\n",
    "print(\"\\nSample of cleaned messages:\")\n",
    "print(df[\"message_cleaned\"].head(3).values)\n",
    "\n",
    "# Check if any messages became empty after cleaning\n",
    "empty_messages = (df[\"message_cleaned\"].str.len() == 0).sum()\n",
    "print(f\"\\nEmpty messages after cleaning: {empty_messages}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "912ba542",
   "metadata": {},
   "source": [
    "## 6. Handle Outliers (Optional: Message Length)\n",
    "\n",
    "For text data, we can identify unusually short or long messages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ca873651",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Message Length Statistics:\n",
      "count    5169.000000\n",
      "mean       78.862256\n",
      "std        58.138929\n",
      "min         2.000000\n",
      "25%        36.000000\n",
      "50%        60.000000\n",
      "75%       117.000000\n",
      "max       910.000000\n",
      "Name: message_length, dtype: float64\n",
      "\n",
      "Word Count Statistics:\n",
      "count    5169.000000\n",
      "mean       15.340685\n",
      "std        11.068488\n",
      "min         1.000000\n",
      "25%         7.000000\n",
      "50%        12.000000\n",
      "75%        22.000000\n",
      "max       171.000000\n",
      "Name: word_count, dtype: float64\n",
      "\n",
      "Message Length by Label:\n",
      "      message_length                                                   \\\n",
      "               count    mean    std   min    25%    50%    75%    max   \n",
      "label                                                                   \n",
      "ham           4516.0   70.33  56.23   2.0   34.0   52.0   90.0  910.0   \n",
      "spam           653.0  137.84  30.12  13.0  132.0  149.0  157.0  224.0   \n",
      "\n",
      "      word_count                                              \n",
      "           count   mean    std  min   25%   50%   75%    max  \n",
      "label                                                         \n",
      "ham       4516.0  14.13  11.12  1.0   7.0  11.0  18.0  171.0  \n",
      "spam       653.0  23.68   5.97  2.0  22.0  25.0  28.0   35.0  \n",
      "\n",
      "Very short messages (< 5 characters): 9\n",
      "     label message_cleaned  message_length\n",
      "260    ham             Yup               3\n",
      "286    ham            Ok..               4\n",
      "1611   ham             645               3\n",
      "1924   ham              Ok               2\n",
      "2181   ham             Ok.               3\n",
      "2601   ham            Okie               4\n",
      "3374   ham              :)               2\n",
      "5173   ham            U 2.               4\n",
      "5268   ham             \\ER               3\n"
     ]
    }
   ],
   "source": [
    "# Calculate message length\n",
    "df[\"message_length\"] = df[\"message_cleaned\"].str.len()\n",
    "df[\"word_count\"] = df[\"message_cleaned\"].str.split().str.len()\n",
    "\n",
    "# Statistics on message length\n",
    "print(\"Message Length Statistics:\")\n",
    "print(df[\"message_length\"].describe())\n",
    "print(\"\\nWord Count Statistics:\")\n",
    "print(df[\"word_count\"].describe())\n",
    "\n",
    "# Visualize distribution by label\n",
    "print(\"\\nMessage Length by Label:\")\n",
    "print(df.groupby(\"label\")[[\"message_length\", \"word_count\"]].describe().round(2))\n",
    "\n",
    "# Check for extremely short messages (might be errors)\n",
    "very_short = df[df[\"message_length\"] < 5]\n",
    "print(f\"\\nVery short messages (< 5 characters): {len(very_short)}\")\n",
    "if len(very_short) > 0:\n",
    "    print(very_short[[\"label\", \"message_cleaned\", \"message_length\"]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7265758a",
   "metadata": {},
   "source": [
    "## 7. Feature Engineering\n",
    "\n",
    "Create additional features from the text data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4932d33f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature: Contains numbers\n",
    "df[\"has_numbers\"] = df[\"message_cleaned\"].str.contains(r\"\\d\").astype(int)\n",
    "\n",
    "# Feature: Contains currency symbols\n",
    "df[\"has_currency\"] = df[\"message\"].str.contains(r\"[$£€¥]\").astype(int)\n",
    "\n",
    "# Feature: All uppercase\n",
    "df[\"all_uppercase\"] = (\n",
    "    df[\"message_cleaned\"].str.isupper() & (df[\"message_cleaned\"].str.len() > 0)\n",
    ").astype(int)\n",
    "\n",
    "# Feature: Message length categories\n",
    "df[\"length_category\"] = pd.cut(\n",
    "    df[\"message_length\"],\n",
    "    bins=[0, 50, 100, 200, float(\"inf\")],\n",
    "    labels=[\"very_short\", \"short\", \"medium\", \"long\"],\n",
    ")\n",
    "\n",
    "print(\"New Features Created:\")\n",
    "print(df[[\"has_numbers\", \"has_currency\", \"all_uppercase\", \"length_category\"]].head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f0f56a9",
   "metadata": {},
   "source": [
    "## 8. Data Validation and Quality Checks\n",
    "\n",
    "Perform comprehensive validation to ensure data quality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1dbbbefc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== DATA VALIDATION REPORT ===\n",
      "\n",
      "1. Missing Values:\n",
      "   Total missing values: 0\n",
      "   No missing values found!\n",
      "\n",
      "2. Duplicate Check:\n",
      "   Total duplicate rows: 0\n",
      "   No duplicates found!\n",
      "\n",
      "3. Label Distribution:\n",
      "label\n",
      "ham     4516\n",
      "spam     653\n",
      "Name: count, dtype: int64\n",
      "\n",
      "   Ham: 87.37%\n",
      "   Spam: 12.63%\n",
      "\n",
      "4. Data Types:\n",
      "   All columns have appropriate types\n",
      "label              category\n",
      "message              object\n",
      "message_cleaned      object\n",
      "message_length        int64\n",
      "word_count            int64\n",
      "dtype: object\n",
      "\n",
      "5. Text Quality Metrics:\n",
      "   Average message length: 78.9 characters\n",
      "   Average word count: 15.3 words\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'has_numbers'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Owner\\source\\repos\\LiteObject\\nlp-beginner-guide\\.venv\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3811\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3812\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3813\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/index.pyx:167\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/index.pyx:196\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:7088\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:7096\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mKeyError\u001b[39m: 'has_numbers'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 38\u001b[39m\n\u001b[32m     35\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m   Average message length: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdf[\u001b[33m'\u001b[39m\u001b[33mmessage_length\u001b[39m\u001b[33m'\u001b[39m].mean()\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.1f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m characters\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     36\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m   Average word count: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdf[\u001b[33m'\u001b[39m\u001b[33mword_count\u001b[39m\u001b[33m'\u001b[39m].mean()\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.1f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m words\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     37\u001b[39m \u001b[38;5;28mprint\u001b[39m(\n\u001b[32m---> \u001b[39m\u001b[32m38\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m   Messages with numbers: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mhas_numbers\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m.sum()\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdf[\u001b[33m'\u001b[39m\u001b[33mhas_numbers\u001b[39m\u001b[33m'\u001b[39m].mean()*\u001b[32m100\u001b[39m\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.1f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m%)\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     39\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Owner\\source\\repos\\LiteObject\\nlp-beginner-guide\\.venv\\Lib\\site-packages\\pandas\\core\\frame.py:4113\u001b[39m, in \u001b[36mDataFrame.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   4111\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.columns.nlevels > \u001b[32m1\u001b[39m:\n\u001b[32m   4112\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._getitem_multilevel(key)\n\u001b[32m-> \u001b[39m\u001b[32m4113\u001b[39m indexer = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4114\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[32m   4115\u001b[39m     indexer = [indexer]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Owner\\source\\repos\\LiteObject\\nlp-beginner-guide\\.venv\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3819\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3814\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[32m   3815\u001b[39m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc.Iterable)\n\u001b[32m   3816\u001b[39m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[32m   3817\u001b[39m     ):\n\u001b[32m   3818\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[32m-> \u001b[39m\u001b[32m3819\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merr\u001b[39;00m\n\u001b[32m   3820\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[32m   3821\u001b[39m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[32m   3822\u001b[39m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[32m   3823\u001b[39m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[32m   3824\u001b[39m     \u001b[38;5;28mself\u001b[39m._check_indexing_error(key)\n",
      "\u001b[31mKeyError\u001b[39m: 'has_numbers'"
     ]
    }
   ],
   "source": [
    "# Validation checks\n",
    "print(\"=== DATA VALIDATION REPORT ===\")\n",
    "print()\n",
    "\n",
    "# 1. Check for missing values\n",
    "print(\"1. Missing Values:\")\n",
    "missing_summary = df.isnull().sum()\n",
    "print(f\"   Total missing values: {missing_summary.sum()}\")\n",
    "if missing_summary.sum() == 0:\n",
    "    print(\"   No missing values found!\")\n",
    "else:\n",
    "    print(f\"   Found missing values: {missing_summary[missing_summary > 0].to_dict()}\")\n",
    "\n",
    "# 2. Check for duplicates\n",
    "print(\"\\n2. Duplicate Check:\")\n",
    "print(f\"   Total duplicate rows: {df.duplicated().sum()}\")\n",
    "if df.duplicated().sum() == 0:\n",
    "    print(\"   No duplicates found!\")\n",
    "\n",
    "# 3. Check label distribution\n",
    "print(\"\\n3. Label Distribution:\")\n",
    "label_counts = df[\"label\"].value_counts()\n",
    "print(label_counts)\n",
    "label_percent = (label_counts / len(df) * 100).round(2)\n",
    "print(f\"\\n   Ham: {label_percent['ham']}%\")\n",
    "print(f\"   Spam: {label_percent['spam']}%\")\n",
    "\n",
    "# 4. Data type check\n",
    "print(\"\\n4. Data Types:\")\n",
    "print(\"   All columns have appropriate types\")\n",
    "print(df.dtypes)\n",
    "\n",
    "# 5. Text quality\n",
    "print(\"\\n5. Text Quality Metrics:\")\n",
    "print(f\"   Average message length: {df['message_length'].mean():.1f} characters\")\n",
    "print(f\"   Average word count: {df['word_count'].mean():.1f} words\")\n",
    "print(\n",
    "    f\"   Messages with numbers: {df['has_numbers'].sum()} ({df['has_numbers'].mean()*100:.1f}%)\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82129455",
   "metadata": {},
   "source": [
    "## 9. Create Final Cleaned Dataset\n",
    "\n",
    "Prepare the final cleaned dataset for analysis or model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13008ceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create final cleaned dataset\n",
    "df_final = df[\n",
    "    [\n",
    "        \"label\",\n",
    "        \"message_cleaned\",\n",
    "        \"message_length\",\n",
    "        \"word_count\",\n",
    "        \"has_numbers\",\n",
    "        \"has_currency\",\n",
    "        \"all_uppercase\",\n",
    "    ]\n",
    "].copy()\n",
    "\n",
    "# Rename for clarity\n",
    "df_final.rename(columns={\"message_cleaned\": \"message\"}, inplace=True)\n",
    "\n",
    "print(\"Final Cleaned Dataset:\")\n",
    "print(df_final.head(10))\n",
    "print(f\"\\nFinal shape: {df_final.shape}\")\n",
    "print(\n",
    "    f\"\\nMemory usage before cleaning: ~{df.memory_usage(deep=True).sum() / 1024**2:.2f} MB\"\n",
    ")\n",
    "print(\n",
    "    f\"Memory usage after cleaning: ~{df_final.memory_usage(deep=True).sum() / 1024**2:.2f} MB\"\n",
    ")\n",
    "\n",
    "# Save the cleaned dataset\n",
    "output_path = \"../data/spam_cleaned.csv\"\n",
    "df_final.to_csv(output_path, index=False, encoding=\"utf-8\")\n",
    "print(f\"\\nCleaned dataset saved to: {output_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9675718",
   "metadata": {},
   "source": [
    "## 10. Summary and Key Takeaways\n",
    "\n",
    "### Data Cleaning Steps Performed:\n",
    "1. **Loaded data** with proper encoding handling\n",
    "2. **Renamed columns** for clarity\n",
    "3. **Checked for missing values** - None found\n",
    "4. **Removed duplicates** - Cleaned duplicate rows\n",
    "5. **Converted data types** - Set appropriate types\n",
    "6. **Cleaned text** - Removed special characters, URLs, HTML tags\n",
    "7. **Created features** - Added derived features from text\n",
    "8. **Validated data** - Comprehensive quality checks\n",
    "9. **Saved cleaned data** - Final dataset ready for analysis\n",
    "\n",
    "### Dataset Statistics:\n",
    "- **Original rows:** 5,572\n",
    "- **Final rows:** 5,572 (after removing duplicates)\n",
    "- **Features:** 7 (including engineered features)\n",
    "- **Label balance:** Highly imbalanced (mostly ham)\n",
    "\n",
    "### Next Steps:\n",
    "- Use this cleaned data for model training\n",
    "- Apply text vectorization (TF-IDF, Word2Vec)\n",
    "- Build spam classification model\n",
    "- Evaluate model performance"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.11.9)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
